<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>bigdata | goatwu1993</title>
    <link>https://goatwu1993.github.io/blog/tags/bigdata/</link>
      <atom:link href="https://goatwu1993.github.io/blog/tags/bigdata/index.xml" rel="self" type="application/rss+xml" />
    <description>bigdata</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Thu, 27 Feb 2020 00:00:00 +0000</lastBuildDate>
    <image>
      <url>img/map[gravatar:%!s(bool=false) shape:circle]</url>
      <title>bigdata</title>
      <link>https://goatwu1993.github.io/blog/tags/bigdata/</link>
    </image>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;what-is-hive&#34;&gt;What is Hive&lt;/h2&gt;
&lt;p&gt;Apache Hive æ˜¯åŸºæ–¼ Hadoop çš„ Data warehouse è»Ÿé«”ï¼Œæœ€åˆç”± Facebook é–‹ç™¼ï¼Œç•¶è³‡æ–™é›†å¾ˆå¤§ï¼ŒHive æä¾›ä¸€å€‹é¡ä¼¼ SQL çš„èªè¨€ä»¥ç”¨ä¾†è®€/å¯«/ç®¡ç†å¤§é‡æˆ–åˆ†æ•£å¼çš„æ•¸æ“šé›†&lt;/p&gt;
&lt;h2 id=&#34;what-can-hive-do&#34;&gt;What can hive do&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;å¯ç”¨ SQL å­˜å–æ•¸æ“šçš„å·¥å…·ï¼Œå› æ­¤å¯ä»¥ç”¨ä¾†åšä¸€äº› Datawarehousing å¸¸ç”¨åˆ°çš„å·¥ä½œï¼Œä¾‹å¦‚ ETL, Reporting å’Œè³‡æ–™åˆ†æ&lt;/li&gt;
&lt;li&gt;Hive è¢«ç”¨ä¾† query å’Œç®¡ç†åˆ†æ•£å¼æ•¸ Hadoopï¼Œå¯ä»¥æ˜¯ Apache HDFS æˆ–æ˜¯ Apache HBase&lt;/li&gt;
&lt;li&gt;é€é Apache Tez, Apache Spark æˆ– MapReduce é€²è¡Œ Query execution&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.edureka.co/blog/hive-commands-with-examples&#34;&gt;https://www.edureka.co/blog/hive-commands-with-examples&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/HIVE&#34;&gt;https://cwiki.apache.org/confluence/display/HIVE&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;ç’°å¢ƒé…ç½®&#34;&gt;ç’°å¢ƒé…ç½®&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Java
&lt;ul&gt;
&lt;li&gt;JDK&lt;/li&gt;
&lt;li&gt;è¨­ç½® PATH å’Œ JAVA_HOME è®Šé‡ï¼Œæ·»åŠ ä»¥ä¸‹å‘½ä»¤åˆ°ã€œ/.bashrc æ–‡ä»¶ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Hadoop&lt;/li&gt;
&lt;li&gt;HDFS&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&#34;&gt;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hiveql_select_where.html&#34;&gt;http://tw.gitbook.net/hive/hiveql_select_where.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;hive-æ•¸æ“šé¡å‹&#34;&gt;Hive æ•¸æ“šé¡å‹&lt;/h2&gt;
&lt;p&gt;æœ¬ç« ä»‹ç´¹ Hive ä¸åŒçš„æ•¸æ“šé¡å‹ï¼Œç”¨æ–¼å‰µå»ºè¡¨ã€‚Hive æ‰€æœ‰æ•¸æ“šé¡å‹åˆ†ç‚ºå››ç¨®é¡å‹ï¼Œçµ¦å‡ºå¦‚ä¸‹ï¼š&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Numeric Types&lt;/li&gt;
&lt;li&gt;Date/Time Types&lt;/li&gt;
&lt;li&gt;String Types&lt;/li&gt;
&lt;li&gt;Misc Types&lt;/li&gt;
&lt;li&gt;Complex Types&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&#34;&gt;https://cwiki.apache.org/confluence/display/Hive/LanguageManual+Types&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hive_data_types.html&#34;&gt;http://tw.gitbook.net/hive/hive_data_types.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is hive</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</link>
      <pubDate>Thu, 27 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hive/what-is-hive/</guid>
      <description>&lt;h2 id=&#34;what-is-hiveql&#34;&gt;What is HiveQL&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hive&amp;gt;create schema if not exists test;

hive&amp;gt;create external table if not exists test.test_data (row1 int, row2 int, row3 decimal(10,3), row4 int) row format delimited fields terminated by &#39;,&#39; stored as textfile location &#39;hdfs://172.18.1.1:9000/user/hadoop/test/&#39;;

hive&amp;gt;select * from test.test_data where row3 &amp;gt; 2.499;
SELECT * FROM test.test_data WHERE row3 &amp;gt; 2.499;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&#34;&gt;https://github.com/sciencepal/dockers/tree/master/hadoop_hive_spark_docker&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://tw.gitbook.net/hive/hiveql_select_where.html&#34;&gt;http://tw.gitbook.net/hive/hiveql_select_where.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>pyspark install</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/pyspark-p1-pyspark-install/</link>
      <pubDate>Wed, 26 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/pyspark-p1-pyspark-install/</guid>
      <description>&lt;h2 id=&#34;pyspark&#34;&gt;pyspark&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;apt-get install python3
pip3 install pyspark
pip3 install py4j
pip3 install findspark
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://opensource.com/article/18/11/pyspark-jupyter-notebook&#34;&gt;https://opensource.com/article/18/11/pyspark-jupyter-notebook&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka mechanism</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p5-mechanism/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;h2 id=&#34;producer&#34;&gt;Producer&lt;/h2&gt;
&lt;h3 id=&#34;producer-é€£æ¥&#34;&gt;Producer é€£æ¥&lt;/h3&gt;
&lt;h3 id=&#34;producer-ç™¼é€è¨Šæ¯æ™‚&#34;&gt;Producer ç™¼é€è¨Šæ¯æ™‚&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Zookeeper / bootstrap server&lt;/li&gt;
&lt;li&gt;Topics&lt;/li&gt;
&lt;li&gt;Key(å¯ç‚º Null)&lt;/li&gt;
&lt;li&gt;Value(å¯ç‚º Null)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;broker&#34;&gt;Broker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Topic è¢«åˆ†ç‚ºå¤šå€‹ Partition&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition æœƒæœ‰å¤šå€‹ Replica&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Broker controller&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;å…¶ä¸­ä¸€å€‹ Broker æœƒè¢«æ¨é¸ç‚º Controller&lt;/li&gt;
&lt;li&gt;è² è²¬åµæ¸¬ Broker ç´šåˆ¥çš„ Failureï¼Œå¹«å¿™æ‰€æœ‰å—å½±éŸ¿çš„ Partition æ›´æ› Partition Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka çš„è¨Šæ¯ç‚ºéµå€¼å°ï¼Œä½¿ç”¨éµå€¼å°å¯ä»¥æä¾› Key -&amp;gt; Partition -&amp;gt; Offset çš„æŸ¥è©¢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic ç‚ºè¨Šæ¯çš„æŠ½è±¡åˆ†é¡&lt;/li&gt;
&lt;li&gt;Producers ç™¼é€è¨Šæ¯æ™‚ï¼ŒæœƒæŒ‡å®šä¸€è‡³å¤šå€‹ Topicsã€‚Consumers è¨‚é–±ä¸€æˆ–å¤šå€‹ Topics&lt;/li&gt;
&lt;li&gt;Topics åˆ†ç‚º Regular Topics åŠ Compacted topics&lt;/li&gt;
&lt;li&gt;Regular Topics éœ€è¦è¨­å®š retention timeï¼Œè¶…éå‰‡ Kafka å¯åˆªé™¤è³‡æ–™ä»¥é‡‹å‡ºç¡¬ç¢Ÿç©ºé–“&lt;/li&gt;
&lt;li&gt;Compacted Topics å‰‡è¨Šæ¯æ²’æœ‰æœ‰æ•ˆæœŸé™ï¼Œå”¯è‹¥ Key é‡è¤‡ï¼Œæ–°è¨Šæ¯æœƒè¦†è“‹èˆŠçš„è¨Šæ¯ã€‚Producer å¯ç™¼é€å€¼ç‚º null çš„éµå€¼å°ä»¥æ°¸ä¹…åˆªé™¤è©²è³‡æ–™ï¼Œç¨±ä½œ tombstone message&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;å»ºç«‹ Topic æ™‚éœ€è¦æŒ‡å®š Partitions æ•¸ç›®ï¼Œä¹‹å¾Œåªèƒ½å¢åŠ ä¸èƒ½æ¸›å°‘&lt;/li&gt;
&lt;li&gt;Partition æ˜¯ Queueï¼Œè¨Šæ¯æŒ‰ offset åš´æ ¼æ’åºï¼Œæ–°è¨Šæ¯è¢« append è‡³å°¾ç«¯&lt;/li&gt;
&lt;li&gt;ç”±æ–¼æ˜¯ç£ç¢Ÿçš„é€£çºŒå€åŸŸï¼Œå› æ­¤æ•ˆç‡å¾ˆé«˜&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-offset&#34;&gt;Partition offset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;è¨Šæ¯åœ¨ partition è£¡é¢çš„ indexï¼Œç¨±ä½œ offsetï¼Œç‚º Long å‹æ…‹çš„æ•´æ•¸&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Partition ç”¢ç”Ÿ n å€‹å‰¯æœ¬ï¼Œåˆ†æ•£è‡³å„å€‹ Broker ä¸Šï¼Œn ç¨±ä½œ replication-factor&lt;/li&gt;
&lt;li&gt;æˆåŠŸåŒæ­¥çš„ Replica ç¨±ä½œ 
&lt;a href=&#34;#ISR&#34;&gt;ISR&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;partition-leader&#34;&gt;Partition Leader&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Broker Controller å°æ¯å€‹ Partition æŒ‡å®šä¸€å€‹ Leader&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Partition Leader è² è²¬æ¥æ”¶è³‡æ–™ï¼Œæ¥æ”¶ä¸¦å¯«å…¥å¾Œï¼Œå°‡è³‡æ–™ replicate åˆ°å…¨éƒ¨ replica/partition follower&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;partition-follower&#34;&gt;Partition Follower&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;åŒä¸€ Partition çš„ non-leader replica&lt;/li&gt;
&lt;li&gt;æ¦‚å¿µä¸Šç‚ºåªè¿½éš¨æŸå€‹ partition çš„ Consumerï¼Œåª subscribe partition Leaderï¼Œç™¼ç¾æ›´æ–°æ™‚ pull åˆ°æœ¬åœ°ç«¯&lt;/li&gt;
&lt;li&gt;ç•¶ Partition Leader å¤±æ•ˆï¼ŒBroker Controller å¾ ISR ä¸­é¸å‡ºæ–° Leader&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;h3 id=&#34;isr&#34;&gt;ISR&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ç•¶ Leader æ”¶åˆ°è¨Šæ¯æ™‚ï¼Œæ‰€æœ‰ Follower éƒ½éœ€è¦å¯«å…¥ï¼Œå·²ç¶“æ›´æ–°è‡³å’Œ Leader åŒæ­¥çš„ Followers ç¨±ç‚º ISRs(in-sync replica)&lt;/li&gt;
&lt;li&gt;Record åªæœ‰åœ¨å…¨éƒ¨çš„ ISR éƒ½åŒæ­¥æ™‚ï¼Œæ‰è¢«è¦–ç‚ºæˆåŠŸ Commited&lt;/li&gt;
&lt;li&gt;Consumer åªèƒ½å¾å·²ç¶“ Commit æˆåŠŸçš„ Record è®€å–ç´€éŒ„&lt;/li&gt;
&lt;li&gt;å°æ–¼ä¸€å€‹ Topicï¼Œåªè¦å„å€‹ Partition çš†æœ‰ä¸€å€‹ ISR åœ¨ç·šï¼Œå‰‡å…§å®¹ä¿æŒä¸€è‡´ä¸”æœå‹™ä¸ä¸­æ–·&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-cluster&#34;&gt;Kafka Cluster&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;n å€‹ Broker çµ„æˆ Cluster&lt;/li&gt;
&lt;li&gt;å¯ä»¥ zero downtime æ“´å±•&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;ç®¡ç†å¢é›†é…ç½®&lt;/li&gt;
&lt;li&gt;è² è²¬ç®¡ç†åŠå”èª¿ Broker&lt;/li&gt;
&lt;li&gt;é€šçŸ¥ Producer åŠ Consumer
&lt;ul&gt;
&lt;li&gt;æ–°çš„ Broker å‡ºç¾&lt;/li&gt;
&lt;li&gt;Broker failure&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;ç•¶ Zookeeper ç™¼å‡ºé€šçŸ¥ï¼ŒConsumer åŠ Producer æ ¹æ“šé€šçŸ¥æ±ºå®šè¦ä½¿ç”¨å“ªä¸€å€‹ Broker&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://zookeeper.apache.org/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;https://zookeeper.apache.org/&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-ç°¡æ˜“å…¥é–€-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with multi brokers</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p4-multibrokers/</guid>
      <description>&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;å•Ÿå‹•-zookeeper&#34;&gt;å•Ÿå‹• zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;é–‹å•Ÿä¸‰å€‹-brokers&#34;&gt;é–‹å•Ÿä¸‰å€‹ Brokers&lt;/h2&gt;
&lt;p&gt;åˆ†åˆ«ä¿®æ”¹ server1.properties, server2.properties&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th align=&#34;center&#34;&gt;ä¿®æ”¹ä½ç½®&lt;/th&gt;
&lt;th&gt;server.properties&lt;/th&gt;
&lt;th&gt;server1.properties&lt;/th&gt;
&lt;th&gt;server2.properties&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;broker.id&lt;/td&gt;
&lt;td&gt;broker.id=0&lt;/td&gt;
&lt;td&gt;broker.id=1&lt;/td&gt;
&lt;td&gt;broker.id=2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;listeners&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9092&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9093&lt;/td&gt;
&lt;td&gt;listeners=PLAINTEXT://:9094&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td align=&#34;center&#34;&gt;log.dir&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-0&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-1&lt;/td&gt;
&lt;td&gt;log.dir=/usr/local/var/lib/kafka-logs-2&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-server-start /usr/local/etc/kafka/server.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server1.properties &amp;amp;
kafka-server-start /usr/local/etc/kafka/server2.properties &amp;amp;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;é–‹å•Ÿä¸€å€‹å…©å€‹å‰¯æœ¬çš„-topic&#34;&gt;é–‹å•Ÿä¸€å€‹å…©å€‹å‰¯æœ¬çš„ Topic&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics â€“create â€“zookeeper localhost:2181 â€“replication-factor 3 â€“partitions 1 â€“topic mytopic
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api&#34;&gt;Consumer &amp;amp; Producer API&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
ä½¿ç”¨ brew kafka æä¾›çš„ shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;é–‹å•Ÿå…©å€‹å‘½ä»¤åˆ—&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;./bin/kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‡‰è©²è¦èƒ½çœ‹åˆ°è¨Šæ¯å‚³é€éå»&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/åœ¨-mac-ä¸Šå»ºç«‹-Python-çš„-Kafka-èˆ‡-Spark-ç’°å¢ƒ/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka with single broker</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p3-singlebroker/</guid>
      <description>&lt;h2 id=&#34;install-kafka&#34;&gt;Install Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# this will install java 1.8, zookeeper, and kafka
brew install kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æª”æ¡ˆä½ç½®&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;/usr/local/etc/kafka&lt;/li&gt;
&lt;li&gt;/usr/local/Cellar/kafka/$ç‰ˆè™Ÿ&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;cd /usr/local/Cellar/kafka/*
# å•Ÿå‹•zookeeper
./bin/zookeeper-server-start /usr/local/etc/kafka/zookeeper.properties
# å•Ÿå‹•kafka
./bin/kafka-server-start /usr/local/etc/kafka/server.properties
# å»ºä¸€å€‹åç‚º test-kafka çš„ Topic
./bin/kafka-topics --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test-kafka

# æŸ¥çœ‹ç›®å‰å·²ç¶“å»ºç«‹éçš„ Topic
./bin/kafka-topics --list --zookeeper localhost:2181\n\n
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;å•Ÿå‹•-zookeeper--kafka&#34;&gt;å•Ÿå‹• zookeeper &amp;amp; kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;brew services start zookeeper
brew services start kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;consumer--producer-api-é¸æ“‡&#34;&gt;Consumer &amp;amp; Producer API é¸æ“‡&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Shell script&lt;br&gt;
ä½¿ç”¨ brew kafka æä¾›çš„ shell script&lt;/li&gt;
&lt;li&gt;Python
&lt;ul&gt;
&lt;li&gt;pykafka&lt;/li&gt;
&lt;li&gt;kafka-python&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scala
&lt;ul&gt;
&lt;li&gt;Scala-Shell&lt;/li&gt;
&lt;li&gt;Native-App&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;shell-script&#34;&gt;Shell Script&lt;/h2&gt;
&lt;p&gt;é–‹å•Ÿå…©å€‹å‘½ä»¤åˆ—&lt;/p&gt;
&lt;p&gt;console1&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list localhost:9092 --topic test-kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;console2&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-consumer --bootstrap-server localhost:9092 --topic test-kafka --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‡‰è©²è¦èƒ½çœ‹åˆ° console1 çš„è¼¸å…¥&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://oumuv.github.io/2018/12/06/kafka-2/&#34;&gt;https://oumuv.github.io/2018/12/06/kafka-2/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://blog.v123582.tw/2019/03/27/%E5%9C%A8-mac-%E4%B8%8A%E5%BB%BA%E7%AB%8B-Python-%E7%9A%84-Kafka-%E8%88%87-Spark-%E7%92%B0%E5%A2%83/&#34;&gt;https://blog.v123582.tw/2019/03/27/åœ¨-mac-ä¸Šå»ºç«‹-Python-çš„-Kafka-èˆ‡-Spark-ç’°å¢ƒ/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Some of Kafka terminology</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p2-terminology/</guid>
      <description>&lt;h2 id=&#34;kafka-architecture&#34;&gt;Kafka Architecture&lt;/h2&gt;
&lt;p&gt;&lt;img src=&#34;https://upload.wikimedia.org/wikipedia/commons/thumb/6/64/Overview_of_Apache_Kafka.svg/1920px-Overview_of_Apache_Kafka.svg.png&#34; alt=&#34;Picture from wiki&#34;&gt;&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;producers&#34;&gt;Producers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;è² è²¬å°‡è¨Šæ¯ push åˆ° Kafka clusterï¼Œä»»ä½•å¯¦ä½œ Producer API çš„ Client&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;consumers&#34;&gt;Consumers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;å¾ Kafka cluster pull è¨Šæ¯ï¼Œä»»ä½•å¯¦ä½œ Consumer API çš„ Client&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Consumer group&lt;/strong&gt;: å¤šå€‹ Consumer å¯çµ„æˆ Consumer group&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;brokers&#34;&gt;Brokers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Broker&lt;/strong&gt;: Kafka çš„å–®ä¸€ç¯€é»ç¨±ä½œ Broker&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Kafka Cluster&lt;/strong&gt;: å¤šå€‹ broker çµ„æˆ Kafka Cluster&lt;/li&gt;
&lt;li&gt;Broker å¯ä»¥èªªæ˜¯ Apache Kafka çš„ Server ç«¯ï¼Œä»²ä»‹è™•ç† Client(Consumer ä»¥åŠ Producer)çš„è¨Šæ¯&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;message&#34;&gt;Message&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Kafka çš„è¨Šæ¯ç‚ºéµå€¼å°ï¼Œæä¾› Topic + Key å° Partition çš„æŸ¥è©¢&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;topic&#34;&gt;Topic&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Topic ç‚ºè¨Šæ¯çš„æŠ½è±¡åˆ†é¡&lt;/li&gt;
&lt;li&gt;Producers ç™¼é€è¨Šæ¯æ™‚æŒ‡å®š Topic&lt;/li&gt;
&lt;li&gt;Consumers è¨‚é–± Topic&lt;/li&gt;
&lt;li&gt;Topic è¢«åˆ†ç‚ºå¤šå€‹ Partition&lt;/li&gt;
&lt;li&gt;Partition æœƒæœ‰å¤šå€‹ Replica&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;partition&#34;&gt;Partition&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;å»ºç«‹ Topic æ™‚éœ€è¦æŒ‡å®š Partitions æ•¸ç›®ï¼ŒTopic æœƒè¢«åˆ†ç‚ºå¤šå€‹ Partitionï¼ŒPartition æ•¸ç›®ä¹‹å¾Œåªèƒ½å¢åŠ ä¸èƒ½æ¸›å°‘&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Partition offset&lt;/strong&gt;: è¨Šæ¯åœ¨ partition è£¡é¢çš„ indexï¼Œç¨±ä½œ offsetï¼Œç‚º Long å‹æ…‹çš„æ•´æ•¸&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;replica&#34;&gt;Replica&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;replication-factor&lt;/strong&gt;: Partition ç”¢ç”Ÿ n å€‹å‰¯æœ¬ï¼Œåˆ†æ•£è‡³å„å€‹ Broker ä¸Š&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ISR&lt;/strong&gt;: æˆåŠŸåŒæ­¥çš„ Replica ç¨±ä½œ ISR&lt;/li&gt;
&lt;li&gt;Replica ç”¨æ–¼ä¿è­‰åˆ†æ•£å¼ç³»çµ±çš„é«˜å¯ç”¨&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;ZooKeeper&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apache çš„å¦ä¸€å€‹åˆ†æ•£å¼å°ˆæ¡ˆï¼Œå¯ç®¡ç†ç³»çµ±é…ç½®&lt;/li&gt;
&lt;li&gt;è² è²¬ Kafka çš„ä»¥ä¸‹åŠŸèƒ½
&lt;ul&gt;
&lt;li&gt;å„²å­˜ metadata&lt;/li&gt;
&lt;li&gt;é¸èˆ‰ controller/leader&lt;/li&gt;
&lt;li&gt;Consumer group ç™¼ç”Ÿè®ŠåŒ–æ™‚ï¼Œé€²è¡Œ rebalance&lt;/li&gt;
&lt;li&gt;ç•¶ Producer æŒ‡å®š ZK(è€Œé bootstrap server)ï¼ŒZK è² è²¬è¿”å› broker list&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kafka Improvement Proposals å·²ç¶“é€šéï¼Œå°‡ Zookeeper å¾ Kafka ç§»é™¤ï¼Œä½¿ç”¨ bootstrap server/broker controller/å…±è­˜ä¾†ç¶­è­· Kafka ï¼Œ&lt;a href=&#34;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&#34;&gt;https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&#34;&gt;https://github.com/abhioncbr/Kafka-Message-Server/wiki/Apache-of-Kafka-Architecture-(As-per-Apache-Kafka-0.8.0-Dcoumentation)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-ç°¡æ˜“å…¥é–€-db58898a3fab&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;http://cloudurable.com/blog/kafka-architecture-topics/index.html&#34;&gt;http://cloudurable.com/blog/kafka-architecture-topics/index.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&#34;&gt;https://gitbook.cn/books/5ae1e77197c22f130e67ec4e/index.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p1-whatishadoop/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p1-whatishadoop/</guid>
      <description>&lt;h2 id=&#34;what-is-hadoop&#34;&gt;What is Hadoop&lt;/h2&gt;
&lt;p&gt;Apache Hadoop æ˜¯ä¸€æ¬¾æ”¯æ´è³‡æ–™å¯†é›†å‹åˆ†å¸ƒå¼æ‡‰ç”¨ç¨‹å¼ä¸¦ä»¥ Apache 2.0 è¨±å¯å”å®šç™¼å¸ƒçš„é–‹æºè»Ÿé«”æ¡†æ¶ã€‚å®ƒæ”¯æ´åœ¨å•†å“ç¡¬é«”æ§‹å»ºçš„å¤§å‹å¢é›†ä¸Šé‹è¡Œçš„æ‡‰ç”¨ç¨‹å¼ã€‚Hadoop æ˜¯æ ¹æ“š Google å…¬å¸ç™¼è¡¨çš„ MapReduce å’Œ Google æª”æ¡ˆç³»çµ±çš„è«–æ–‡è‡ªè¡Œå¯¦ä½œè€Œæˆã€‚æ‰€æœ‰çš„ Hadoop æ¨¡çµ„éƒ½æœ‰ä¸€å€‹åŸºæœ¬å‡è¨­ï¼Œå³ç¡¬é«”æ•…éšœæ˜¯å¸¸è¦‹æƒ…æ³ï¼Œæ‡‰è©²ç”±æ¡†æ¶è‡ªå‹•è™•ç†ã€‚&lt;/p&gt;
&lt;p&gt;Hadoop æ¡†æ¶é€æ˜åœ°ç‚ºæ‡‰ç”¨æä¾›å¯é æ€§å’Œè³‡æ–™ç§»å‹•ã€‚å®ƒå¯¦ç¾äº†åç‚º MapReduce çš„ç·¨ç¨‹ç¯„å¼ï¼šæ‡‰ç”¨ç¨‹å¼è¢«åˆ†å‰²æˆè¨±å¤šå°éƒ¨åˆ†ï¼Œè€Œæ¯å€‹éƒ¨åˆ†éƒ½èƒ½åœ¨å¢é›†ä¸­çš„ä»»æ„ç¯€é»ä¸ŠåŸ·è¡Œæˆ–é‡æ–°åŸ·è¡Œã€‚æ­¤å¤–ï¼ŒHadoop é‚„æä¾›äº†åˆ†å¸ƒå¼æª”æ¡ˆç³»çµ±ï¼Œç”¨ä»¥å„²å­˜æ‰€æœ‰è¨ˆç®—ç¯€é»çš„è³‡æ–™ï¼Œé€™ç‚ºæ•´å€‹å¢é›†å¸¶ä¾†äº†éå¸¸é«˜çš„å¸¶å¯¬ã€‚MapReduce å’Œåˆ†å¸ƒå¼æª”æ¡ˆç³»çµ±çš„è¨­è¨ˆï¼Œä½¿å¾—æ•´å€‹æ¡†æ¶èƒ½å¤ è‡ªå‹•è™•ç†ç¯€é»æ•…éšœã€‚å®ƒä½¿æ‡‰ç”¨ç¨‹å¼èˆ‡æˆåƒä¸Šè¬çš„ç¨ç«‹è¨ˆç®—çš„é›»è…¦å’Œ PB ç´šçš„è³‡æ–™é€£æ¥èµ·ä¾†ã€‚&lt;/p&gt;
&lt;h2 id=&#34;how-hadoop-work&#34;&gt;How Hadoop work&lt;/h2&gt;
&lt;p&gt;Hadoop ç”±å››å€‹çµ„ä»¶çµ„æˆ&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hadoop Distributed File System (HDFS)&lt;/strong&gt;
&lt;strong&gt;MapReduce&lt;/strong&gt;: å¹³è¡Œè¨ˆç®—æ¡†æ¶
&lt;strong&gt;YARN&lt;/strong&gt;: Yet Another Resource Negotiator.
&lt;strong&gt;Hadoop Common&lt;/strong&gt;: åŸºæœ¬çš„å·¥å…·(Java)ï¼Œè®“ä½¿ç”¨è€…æˆ– OS å¯ä»¥å’Œ HDFS äº’å‹•&lt;/p&gt;
&lt;h3 id=&#34;hadoop-eco-system&#34;&gt;Hadoop eco-system&lt;/h3&gt;
&lt;p&gt;Spark, HBAse, Hive, Kafka, HDFS, etc&lt;/p&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;ç³»çµ±éœ€æ±‚&#34;&gt;ç³»çµ±éœ€æ±‚&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;docker&#34;&gt;Docker&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://hadoop.apache.org/releases.html&#34;&gt;https://hadoop.apache.org/releases.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Hadoop</title>
      <link>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-hadoop/hadoop-p2-hdfs-install/</guid>
      <description>&lt;h2 id=&#34;commands&#34;&gt;Commands&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;start-dfs.sh
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hdfs namenode -format
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;referencce&#34;&gt;Referencce&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Apache_Hadoop&#34;&gt;https://zh.wikipedia.org/wiki/Apache_Hadoop&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://kknews.cc/zh-tw/code/rlyqae4.html&#34;&gt;https://kknews.cc/zh-tw/code/rlyqae4.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-elk/kafka-p1/</guid>
      <description>&lt;h2 id=&#34;what-is-elk&#34;&gt;What is ELK&lt;/h2&gt;
&lt;p&gt;ELK æ˜¯ç”± Elasticsearch, Logstash åŠ Kibana çµ„æˆçš„å †ç–Š
ç”±æ–¼ Logstash æ•ˆèƒ½ä¸ä½³ï¼Œå› æ­¤å¾Œé¢åŠ å…¥äº† Beatsï¼Œç¨±ä½œ Elastic Stack
ä»¥ä¸Šè»Ÿé«”çš†ç”± Elastic NV é–‹ç™¼ã€‚&lt;/p&gt;
&lt;h2 id=&#34;what-is-elasticsearch&#34;&gt;What is Elasticsearch&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Elasticsearch æ˜¯å€‹åˆ†æ•£å¼ï¼Œæ”¯æ´å¤šç§Ÿæˆ¶çš„å…¨æ–‡æœå°‹å¼•æ“ï¼Œä»–çš„æœå°‹å¼•æ“æ˜¯åŸºæ–¼ Apache Lucene æ”¹å¯«ã€‚&lt;/li&gt;
&lt;li&gt;Elasticsearch ç”± Java ç·¨å¯«ï¼Œç›®å‰ç”± Elastic NV å…¬å¸ç¶­è­·ï¼Œæ ¸å¿ƒåŸå§‹ç¢¼ç‚º Apache 2.0 é–‹æºï¼Œå¹³å°åŠå‘¨é‚ŠåŸºæ–¼ Elastic Licenseã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;elasticsearch-features&#34;&gt;Elasticsearch Features&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;åˆ†æ•£å¼ï¼Œå¯æ“´å±•&lt;/li&gt;
&lt;li&gt;å¤šç§Ÿæˆ¶&lt;/li&gt;
&lt;li&gt;RESTfulï¼Œä½¿ç”¨ JSON å’Œ Java API&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;how-does-elasticsearch-works&#34;&gt;How does Elasticsearch works&lt;/h2&gt;
&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.infoq.cn/article/kafka-analysis-part-1&#34;&gt;https://www.infoq.cn/article/kafka-analysis-part-1&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zhuanlan.zhihu.com/p/96826042&#34;&gt;https://zhuanlan.zhihu.com/p/96826042&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/wiki/Elasticsearch&#34;&gt;https://zh.wikipedia.org/wiki/Elasticsearch&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Kafka</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-p1/</guid>
      <description>&lt;p&gt;Kafka æ˜¯ä¸€å€‹åˆ†æ•£å¼çš„è¨Šæ¯è™•ç†å¹³å°(message processing platform)ï¼Œä»²ä»‹è™•ç†ç«¯åˆ°ç«¯çš„å¯¦æ™‚è¨Šæ¯å‚³è¼¸ã€‚&lt;/p&gt;
&lt;h2 id=&#34;kafka-ç‰¹é»&#34;&gt;Kafka ç‰¹é»&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;åˆ†æ•£å¼&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;å¯ä»¥è‡ªç”±èª¿æ•´ C/A/P&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;æ¸›å°‘ç¶²è·¯å°åŒ…çš„ Overhead&lt;/strong&gt;: ä½¿ç”¨å„ªåŒ–éçš„ binary TCP-based protocolï¼Œå¤šæ¢è¨Šæ¯æœƒå…ˆå¯«å…¥è¨˜æ†¶é«”ç·©è¡ä¸­å­˜æˆ Batch ä¸€åŒå‚³è¼¸ï¼Œ&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;è¼•é‡ç´šå¯å£“ç¸®&lt;/strong&gt;: é¿å…å°è¨Šæ¯çš„ç‰©ä»¶åŒ…è¦†ï¼Œä»¥&lt;strong&gt;æª”æ¡ˆ&lt;/strong&gt;çš„å‹å¼ä¾†è™•ç†è³‡æ–™&lt;/li&gt;
&lt;li&gt;ä½¿ç”¨ OS çš„ page cacheï¼Œä¸éœ€è¦é¡å¤– Applicaion Cache ï¼Œçˆ­å–çè²´çš„è¨˜æ†¶é«”ç©ºé–“&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;kafka-å„ªé»&#34;&gt;Kafka å„ªé»&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Reliability&lt;/li&gt;
&lt;li&gt;Scalability&lt;/li&gt;
&lt;li&gt;Durability&lt;/li&gt;
&lt;li&gt;Performance&lt;/li&gt;
&lt;li&gt;Fault Tolerance&lt;/li&gt;
&lt;li&gt;Zero downtime&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Apache Spark Setup</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/spark-p2-setup/</link>
      <pubDate>Fri, 17 Jan 2020 20:33:38 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/spark-p2-setup/</guid>
      <description>&lt;h2 id=&#34;spark-installation&#34;&gt;Spark Installation&lt;/h2&gt;
&lt;h2 id=&#34;prerequisite&#34;&gt;Prerequisite&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;macOS
&lt;ul&gt;
&lt;li&gt;Homebrew&lt;/li&gt;
&lt;li&gt;xcode-select&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Java&lt;/li&gt;
&lt;li&gt;Scala&lt;/li&gt;
&lt;li&gt;Apache Spark&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;test&#34;&gt;Test&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ spark-shell
...
...
...
scala&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&#34;&gt;https://ithelp.ithome.com.tw/users/20103839/ironman/1210&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&#34;&gt;https://intellipaat.com/blog/tutorial/spark-tutorial/downloading-spark-and-getting-started/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>What is Apache Spark</title>
      <link>https://goatwu1993.github.io/blog/posts/note-spark/spark-p1-whatis/</link>
      <pubDate>Fri, 17 Jan 2020 17:04:13 +0800</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-spark/spark-p1-whatis/</guid>
      <description>&lt;h2 id=&#34;what-is-spark&#34;&gt;What is Spark&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark æ˜¯ä¸€å€‹é–‹æºå¢é›†å¼é‹ç®—ï¼Œç”¨ä¾†æ›¿ä»£ Hadoop Map Reduce çš„éƒ¨åˆ†åŠŸèƒ½&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-mermaid&#34;&gt;graph TD
Spark(Spark) --&amp;gt; Core(Spark Core)
Spark --&amp;gt; D(Spark SQL)
Spark --&amp;gt; E(Spark Streaming)
Spark --&amp;gt; F(MLlib)
Spark --&amp;gt; G(GraphX)
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;spark-ç‰¹é»&#34;&gt;Spark ç‰¹é»&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Spark å…è¨±ç”¨æˆ¶å°‡è³‡æ–™è¼‰å…¥è‡³å¢é›†è¨˜æ†¶é«”ï¼Œä¸¦å¤šæ¬¡å°å…¶é€²è¡ŒæŸ¥è©¢ï¼Œéå¸¸é©åˆç”¨æ–¼æ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•&lt;/li&gt;
&lt;li&gt;æä¾› Java, Scala, Python åŠ R èªè¨€ API&lt;/li&gt;
&lt;li&gt;è¨˜æ†¶é«”å…§çš„å¿«å–è³‡æ–™é›†ï¼Œå¯é€²è¡Œäº’å‹•å¼è³‡æ–™åˆ†æ(ç›¸å°æ–¼ Hadoop MapReduce)&lt;/li&gt;
&lt;li&gt;Scala æˆ– Python ä¸­çš„äº’å‹•å¼å‘½ä»¤åˆ—ä»‹é¢å¯é™ä½æ©«å‘æ“´å±•è³‡æ–™æ¢ç´¢çš„åæ‡‰æ™‚é–“ã€‚&lt;/li&gt;
&lt;li&gt;Spark Streaming å°å³æ™‚è³‡æ–™ä¸²æµçš„è™•ç†å…·æœ‰å¯æ“´å……æ€§ã€é«˜ååé‡ã€å¯å®¹éŒ¯æ€§ç­‰ç‰¹é»ã€‚&lt;/li&gt;
&lt;li&gt;Spark SQL æ”¯æ´çµæ§‹åŒ–å’Œé—œè¯å¼æŸ¥è©¢è™•ç†ï¼ˆSQLï¼‰ã€‚&lt;/li&gt;
&lt;li&gt;MLlib æ©Ÿå™¨å­¸ç¿’æ¼”ç®—æ³•å’Œ Graphx åœ–å½¢è™•ç†æ¼”ç®—æ³•çš„é«˜éšå‡½å¼åº«ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-ç‰¹é»-1&#34;&gt;Spark ç‰¹é»&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;In Memory Storage&lt;/li&gt;
&lt;li&gt;Immutability&lt;br&gt;
é€šé Spark Core RDD çš„æ¦‚å¿µä¾†å„²å­˜æ•¸æ“šï¼ŒRDD è¢«å‰µå»ºä¹‹å¾Œæ²’æœ‰è¾¦æ³•ä¿®æ”¹ï¼ŒTransfromation åªæœƒç”¢ç”Ÿä¸€å€‹æ–°çš„ RDD&lt;/li&gt;
&lt;li&gt;Lazy Evaluation&lt;br&gt;
æ•¸å€¼ç›´åˆ° Action æ‰æœƒè¢«è¨ˆç®—å‡ºä¾†&lt;/li&gt;
&lt;li&gt;Partitioning&lt;br&gt;
è¨ˆç®—æœƒè¢«æŒ‡æ´¾åˆ° RDD Partitionï¼ŒPartition çš„æ•¸ç›®ç›´æ¥é—œä¿‚åˆ°å¹³è¡Œé‹ç®—çš„ç¨‹åº¦ã€‚&lt;/li&gt;
&lt;li&gt;æ”¯æ´å®¹éŒ¯æ©Ÿåˆ¶&lt;br&gt;
ç´€éŒ„å„å€‹ RDD çš„ç”¢ç”Ÿéç¨‹(ç¨±ç‚º RDD Lineage)ï¼Œç•¶ç¯€é»å¤±æ•ˆæ™‚å¯å¾ Parent RDD é‡æ–°æ¨ç®—å¤±æ•ˆç¯€é»çš„ Partitionã€‚&lt;/li&gt;
&lt;li&gt;å®¹éŒ¯æ©Ÿåˆ¶æœ€ä½³åŒ–
Transfromation å‡½æ•¸åˆ†ç‚ºå¯¬ä¾è³´åŠçª„ä¾è³´ï¼Œçª„ä¾è³´çš„æƒ…æ³ä¸‹å¯ç›´æ¥ç”¨ Partition æ¨ç®— Child Partitionï¼Œä¸éœ€æ•´çµ„ RDD å¾æ–°æ¨ç®—ã€‚&lt;/li&gt;
&lt;li&gt;Persistence
å¯ä»¥æ ¹æ“šè³‡æ–™æ˜¯å¦æœƒé‡æ–°ä½¿ç”¨ï¼ŒæŒ‡å®šå­˜æ”¾åœ¨è¨˜æ†¶é«”æˆ–ç£ç¢Ÿã€‚&lt;/li&gt;
&lt;li&gt;No Limitation&lt;br&gt;
RDD çš„æ•¸ç›®åªéœ€è¦è€ƒé‡è¨˜æ†¶é«”ä»¥åŠç¡¬ç¢Ÿï¼Œæ²’æœ‰ç¢ºåˆ‡æ•¸ç›®ä¸Šé™ã€‚&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;spark-core&#34;&gt;Spark Core&lt;/h2&gt;
&lt;p&gt;Spark Core æ˜¯æ•´å€‹å°ˆæ¡ˆçš„åŸºç¤ï¼Œæä¾›äº†åˆ†æ•£å¼ä»»å‹™èª¿åº¦ã€æ’ç¨‹åŠåŸºæœ¬çš„ I/Oï¼Œå…¶åŸºç¤çš„ç¨‹å¼æŠ½è±¡è¢«ç¨±ç‚º Resilient Distributed Dataset (RDD)&lt;/p&gt;
&lt;h2 id=&#34;spark-sql&#34;&gt;Spark SQL&lt;/h2&gt;
&lt;p&gt;Spark SQL åœ¨ Spark æ ¸å¿ƒä¸Šå¸¶å‡ºä¸€ç¨®åç‚º SchemaRDD çš„è³‡æ–™æŠ½è±¡åŒ–æ¦‚å¿µï¼Œæä¾›çµæ§‹åŒ–å’ŒåŠçµæ§‹åŒ–è³‡æ–™ç›¸é—œçš„æ”¯æ´ã€‚Spark SQL æä¾›äº†é ˜åŸŸç‰¹å®šèªè¨€ï¼Œå¯ä½¿ç”¨ Scalaã€Java æˆ– Python ä¾†æ“ç¸± SchemaRDDsã€‚å®ƒé‚„æ”¯æ´ä½¿ç”¨ä½¿ç”¨å‘½ä»¤è¡Œä»‹é¢å’Œ ODBCï¼JDBC ä¼ºæœå™¨æ“ä½œ SQL èªè¨€ã€‚åœ¨ Spark 1.3 ç‰ˆæœ¬ï¼ŒSchemaRDD è¢«é‡æ–°å‘½åç‚º DataFrameã€‚&lt;/p&gt;
&lt;h2 id=&#34;spark-streaming&#34;&gt;Spark Streaming&lt;/h2&gt;
&lt;p&gt;Spark Streaming å……åˆ†åˆ©ç”¨ Spark æ ¸å¿ƒçš„å¿«é€Ÿæ’ç¨‹èƒ½åŠ›ä¾†åŸ·è¡Œä¸²æµåˆ†æã€‚å®ƒæ“·å–å°æ‰¹æ¬¡çš„è³‡æ–™ä¸¦å°ä¹‹åŸ·è¡Œ RDD è½‰æ›ã€‚é€™ç¨®è¨­è¨ˆä½¿ä¸²æµåˆ†æå¯åœ¨åŒä¸€å€‹å¼•æ“å…§ä½¿ç”¨åŒä¸€çµ„ç‚ºæ‰¹æ¬¡åˆ†æç·¨å¯«è€Œæ’°å¯«çš„æ‡‰ç”¨ç¨‹å¼ç¢¼ã€‚&lt;/p&gt;
&lt;h2 id=&#34;mllib&#34;&gt;MLlib&lt;/h2&gt;
&lt;p&gt;MLlib æ˜¯ Spark ä¸Šåˆ†æ•£å¼æ©Ÿå™¨å­¸ç¿’æ¡†æ¶ã€‚Spark åˆ†æ•£å¼è¨˜æ†¶é«”å¼çš„æ¶æ§‹æ¯” Hadoop ç£ç¢Ÿå¼çš„ Apache Mahout å¿«ä¸Š 10 å€ï¼Œæ“´å……æ€§ç”šè‡³æ¯” Vowpal Wabbit è¦å¥½ã€‚MLlib å¯ä½¿ç”¨è¨±å¤šå¸¸è¦‹çš„æ©Ÿå™¨å­¸ç¿’å’Œçµ±è¨ˆæ¼”ç®—æ³•ï¼Œç°¡åŒ–å¤§è¦æ¨¡æ©Ÿå™¨å­¸ç¿’æ™‚é–“&lt;/p&gt;
&lt;h2 id=&#34;graphx&#34;&gt;GraphX&lt;/h2&gt;
&lt;p&gt;GraphX æ˜¯ Spark ä¸Šçš„åˆ†æ•£å¼åœ–å½¢è™•ç†æ¡†æ¶ã€‚å®ƒæä¾›äº†ä¸€çµ„ APIï¼Œå¯ç”¨æ–¼è¡¨é”åœ–è¡¨è¨ˆç®—ä¸¦å¯ä»¥é¡æ¯” Pregel æŠ½è±¡åŒ–ã€‚GraphX é‚„å°é€™ç¨®æŠ½è±¡åŒ–æä¾›äº†æœ€ä½³åŒ–é‹è¡Œã€‚&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://zh.wikipedia.org/zh-tw/Apache_Spark&#34;&gt;https://zh.wikipedia.org/zh-tw/Apache_Spark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.quora.com/What-are-the-advantages-of-RDD&#34;&gt;https://www.quora.com/What-are-the-advantages-of-RDD&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://codertw.com/%E7%A8%8B%E5%BC%8F%E8%AA%9E%E8%A8%80/405603/&#34;&gt;https://codertw.com/ç¨‹å¼èªè¨€/405603/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka &#43; ELK</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;h2 id=&#34;repos&#34;&gt;Repos&lt;/h2&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-dockers&#34;&gt;https://github.com/wurstmeister/kafka-dockers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&#34;ç’°å¢ƒ&#34;&gt;ç’°å¢ƒ&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;macOS Catalina 10.15.3&lt;/li&gt;
&lt;li&gt;kafka 2.4.0 (installed by Homebrew)&lt;/li&gt;
&lt;li&gt;Docker Desktop 2.2.0.0&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;æº–å‚™-image&#34;&gt;æº–å‚™ Image&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;wurstmeister/zookeeper&lt;/li&gt;
&lt;li&gt;wurstmeister/kafka&lt;/li&gt;
&lt;li&gt;sebp/elk&lt;/li&gt;
&lt;/ul&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker pull wurstmeister/zookeeper
docker pull wurstmeister/kafka
docker pull sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;zookeeper&#34;&gt;Zookeeper&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --name zk -p 2181:2181 -p 2888:2888 -p 3888:3888 --restart always -d zookeeper
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;kafka&#34;&gt;Kafka&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;
docker run -d --name kafka -p 9092:9092 --link zk --env KAFKA_ZOOKEEPER_CONNECT=zk:2181 --env KAFKA_ADVERTISED_HOST_NAME=${host_ip} --env KAFKA_ADVERTISED_PORT=9092 wurstmeister/kafka
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é–‹å€‹ Topics æ¸¬è©¦ä¸€ä¸‹&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;host_ip=&amp;quot;HOST_IP&amp;quot;

kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic elk_test

kafka-topics --describe --zookeeper ${host_ip}:2181
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;ä¸æ”¾å¿ƒçš„è©±å†å¯«å€‹è¨Šæ¯&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-topics --create --zookeeper ${host_ip}:2181 --replication-factor 1 --partitions 1 --topic kfk_test

kafka-console-producer --broker-list ${host_ip}:9092 --topic kfk_test
&amp;gt;
# è¼¸å…¥
# Control+C é—œæ‰

kafka-console-consumer --topic=kfk_test --bootstrap-server=${host_ip}:9092 --from-beginning
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;elk&#34;&gt;ELK&lt;/h2&gt;
&lt;p&gt;Elasticsearch å¥½åƒå¾ˆåƒ Memory&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;screen /Users/peteeelol/Library/Containers/com.docker.docker/Data//vms/0/tty

sysctl -w vm.max_map_count=262144
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run -d -p 5601:5601 -p 9200:9200 -p 9300:9300 -p 5044:5044 -e ES_MIN_MEM=128m -e ES_MAX_MEM=2048m -it --name elk sebp/elk
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æª¢æŸ¥&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Kibana
open http://&amp;quot;${host_ip}&amp;quot;:5601

# docker
$ docker exec elk jps
105 Elasticsearch
313 Logstash
415 Jps
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;è¨­å®š-logstash&#34;&gt;è¨­å®š Logstash&lt;/h2&gt;
&lt;h3 id=&#34;ç°¡å–®æ¸¬è©¦&#34;&gt;ç°¡å–®æ¸¬è©¦&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;$ docker exec -it elk /bin/bash

service --status-all

service logstash stop

/opt/logstash/bin/logstash -e &#39;input { stdin { } } output { elasticsearch { hosts =&amp;gt; [&amp;quot;localhost&amp;quot;] } }&#39;
...
...
...
Hello
# Control + C é›¢é–‹stdin
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æœ€å¾Œä¸€å€‹æŒ‡ä»¤éœ€è¦è·‘ä¸€ä¸‹ï¼Œæ¥è‘—è¼¸å…¥ä¸€äº›è¨Šæ¯&lt;/p&gt;
&lt;p&gt;é›¢é–‹ Docker ç”¨ Host(Mac) æ‰“é–‹ç€è¦½å™¨&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;open http://localhost:9200/_search?pretty
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;æ‡‰è©²è¦èƒ½çœ‹åˆ°å‰›å‰› stdin è¼¸å…¥çš„è¨Šæ¯&lt;/p&gt;
&lt;h3 id=&#34;è¨­å®šæª”&#34;&gt;è¨­å®šæª”&lt;/h3&gt;
&lt;p&gt;å›åˆ° Container elk&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/logstash/conf.d/kafka.conf
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;input {
    kafka {
        bootstrap_servers =&amp;gt; [&amp;quot;HOST_IP:9092&amp;quot;]
        group_id =&amp;gt; &amp;quot;test-consumer-group&amp;quot;
        auto_offset_reset =&amp;gt; &amp;quot;latest&amp;quot;
        consumer_threads =&amp;gt; 5
        decorate_events =&amp;gt; true
        topics =&amp;gt; [&amp;quot;elk_topics&amp;quot;]
        type =&amp;gt; &amp;quot;bhy&amp;quot;
    }
}

output {
    elasticsearch {
        hosts =&amp;gt; [&amp;quot;http://localhost:9200&amp;quot;]
        index =&amp;gt; &amp;quot;myservice-%{+YYYY.MM.dd}&amp;quot;
        #user =&amp;gt; &amp;quot;elastic&amp;quot;
        #password =&amp;gt; &amp;quot;changeme&amp;quot;
    }
}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;æ›´æ”¹-logstash-æ¬Šé™&#34;&gt;æ›´æ”¹ Logstash æ¬Šé™&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;vim /etc/init.d/logstash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å°‡ LS_USER, LS_GROUP æ›´æ”¹ç‚º root&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-vim&#34;&gt;LS_USER=root
LS_GROUP=root
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;å†æŠŠ Logstash é‡è·‘&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;service logstash restart
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;é€™æ™‚å€™ Logstash æ‡‰è©²å°±æœ‰åœ¨æ¥æ”¶ Kafka çš„ elk_topics é€™å€‹ Topic äº†ï¼Œå¯ä»¥ç”¨ Host ç™¼é€è¨Šæ¯æ¸¬è©¦çœ‹çœ‹&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;kafka-console-producer --broker-list ${host_ip}:9092 --topic elk_topics
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;åœ¨ Kibana æ‡‰è©²è¦çœ‹åˆ° index ç‚º my-service é–‹é ­çš„è¨Šæ¯ï¼Œä»£è¡¨è¨Šæ¯é€é Kafka-&amp;gt; Logstash -&amp;gt; Elastic Search&lt;/p&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&#34;&gt;https://medium.com/@poyu677/apache-kafka-%E7%B0%A1%E6%98%93%E5%85%A5%E9%96%80-db58898a3fab&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&#34;&gt;https://github.com/wurstmeister/kafka-docker/wiki/Connectivity&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;https://github.com/sermilrod/kafka-elk-docker-compose&#34;&gt;https://github.com/sermilrod/kafka-elk-docker-compose&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
    <item>
      <title>Kafka Connect Quickstart</title>
      <link>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</link>
      <pubDate>Thu, 30 Jan 2020 00:00:00 +0000</pubDate>
      <guid>https://goatwu1993.github.io/blog/posts/note-kafka/kafka-elk/</guid>
      <description>&lt;p&gt;Slighty modified from Confluent&#39;s example. Only version is updated.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;confluent platform docker version 5.4.0&lt;/li&gt;
&lt;li&gt;mysql version 8.0.19&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Note that docker-compose.yml is slightly modified from 
&lt;a href=&#34;https://github.com/confluentinc/cp-docker-images/blob/5.3.0-post/examples/cp-all-in-one/docker-compose.yml&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;cp-all-in-one&lt;/a&gt;
 in order to be easily understood.&lt;/p&gt;
&lt;p&gt;The docker images is &lt;strong&gt;NOT Size-Mininized&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;prerequisites&#34;&gt;Prerequisites&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Docker&lt;/li&gt;
&lt;li&gt;Docker Compose&lt;/li&gt;
&lt;li&gt;curl&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Docker-Machine&lt;/strong&gt;&lt;br&gt;
Docker for mac is not as native as Linux. Weird network behavior may occur.&lt;br&gt;
Better use docker-machine to avoid it.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;mac-start-docker-machine&#34;&gt;(Mac) Start Docker-Machine&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine create --driver virtualbox --virtualbox-memory 6000 confluent
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Docker machine &amp;quot;confluent&amp;quot; already exists
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-machine start confluent
echo &amp;quot;continue&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Starting &amp;quot;confluent&amp;quot;...
Machine &amp;quot;confluent&amp;quot; is already running.
continue
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    eval $(docker-machine env confluent)
else
    echo &amp;quot;Docker is native on your system&amp;quot;
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;download-mysql-jdbc-driver&#34;&gt;Download MySQL JDBC Driver&lt;/h2&gt;
&lt;p&gt;It is important to make sure the &lt;strong&gt;version of MySQL-JDBC&lt;/strong&gt; match &lt;strong&gt;the version of MySQL&lt;/strong&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
echo
docker-compose rm -f
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center  ...
Stopping connect         ...
Stopping schema-registry ...
Stopping broker          ...
Stopping zookeeper       ...
[1Bping zookeeper       ... [32mdone[0m
Going to remove control-center, quickstart-mysql, connect, schema-registry, broker, zookeeper
Removing control-center   ...
Removing quickstart-mysql ...
Removing connect          ...
Removing schema-registry  ...
Removing broker           ...
Removing zookeeper        ...
[6Bving control-center   ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker run --rm mysql --version
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;/usr/sbin/mysqld  Ver 8.0.19 for Linux on x86_64 (MySQL Community Server - GPL)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- \
    &amp;quot;&amp;quot;&amp;quot;
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
    &amp;quot;&amp;quot;&amp;quot;
else
    sudo mkdir -p /tmp/quickstart/jars;
    sudo curl -k \
        -s \
        -SL \
        \&amp;quot;http://dev.mysql.com/get/Downloads/Connector-J/mysql-connector-java-8.0.19.tar.gz\&amp;quot; |
        sudo tar -xzf - -C \
            /tmp/quickstart/jars \
            --strip-components=1 \
            mysql-connector-java-8.0.19/mysql-connector-java-8.0.19.jar;
    ls -la /tmp/quickstart/jars
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x    2 root     root          4096 Mar  2 22:27 .
drwxr-xr-x    4 root     root          4096 Mar  2 22:19 ..
-rw-r--r--    1 root     root       2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;mysql-jdbc&#34;&gt;MySQL-JDBC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;a href=&#34;https://dev.mysql.com/downloads/connector/j/&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;MySQL Engineering Blogs&lt;/a&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;a href=&#34;https://mvnrepository.com/artifact/mysql/mysql-connector-java/8.0.19&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;mvnrepository&lt;/a&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;start-docker-compose&#34;&gt;Start Docker Compose&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose up -d
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Creating zookeeper ...
[1BCreating broker    ... mdone[0m
[1BCreating schema-registry ... [0m
[1BCreating connect         ... mdone[0m
[1BCreating control-center  ... mdone[0m
Creating quickstart-mysql ...
[1Bting quickstart-mysql ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;insert-data-into-mysql&#34;&gt;Insert data into MySQL&lt;/h2&gt;
&lt;p&gt;MySQL container may take a while until it can function.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Nasty script to wait for mysql be ready
while ! docker exec quickstart-mysql mysql --user=confluent --password=confluent -e &amp;quot;SELECT 1&amp;quot; &amp;gt;/dev/null 2&amp;gt;&amp;amp;1; do
    sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec -i quickstart-mysql mysql -u confluent -pconfluent &amp;lt;&amp;lt;&amp;lt; &amp;quot;&amp;quot;&amp;quot;
CREATE DATABASE IF NOT EXISTS connect_test;
USE connect_test;

DROP TABLE IF EXISTS test;

CREATE TABLE IF NOT EXISTS test (
  id serial NOT NULL PRIMARY KEY,
  name varchar(100),
  email varchar(200),
  department varchar(200),
  modified timestamp default CURRENT_TIMESTAMP NOT NULL,
  INDEX \`modified_index\` (\`modified\`)
);

INSERT INTO test (name, email, department) VALUES (&#39;alice&#39;, &#39;alice@abc.com&#39;, &#39;engineering&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
INSERT INTO test (name, email, department) VALUES (&#39;bob&#39;, &#39;bob@abc.com&#39;, &#39;sales&#39;);
SELECT * FROM test;
&amp;quot;&amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;mysql: [Warning] Using a password on the command line interface can be insecure.
id	name	email	department	modified
1	alice	alice@abc.com	engineering	2020-03-02 22:29:15
2	bob	bob@abc.com	sales	2020-03-02 22:29:15
3	bob	bob@abc.com	sales	2020-03-02 22:29:15
4	bob	bob@abc.com	sales	2020-03-02 22:29:15
5	bob	bob@abc.com	sales	2020-03-02 22:29:15
6	bob	bob@abc.com	sales	2020-03-02 22:29:15
7	bob	bob@abc.com	sales	2020-03-02 22:29:15
8	bob	bob@abc.com	sales	2020-03-02 22:29:15
9	bob	bob@abc.com	sales	2020-03-02 22:29:15
10	bob	bob@abc.com	sales	2020-03-02 22:29:15
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;source-connector&#34;&gt;Source Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-source-connector&#34;&gt;Add source connector&lt;/h3&gt;
&lt;p&gt;Either API or Web UI(Confluent Platform) will acheive the goal.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;export CONNECT_NET=&amp;quot;kafka-connect-mysql_default&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;We have to wait for Kafka Connect to totally start up.&lt;/p&gt;
&lt;p&gt;To speed up the process, remove some directory from &lt;strong&gt;CONNECT_PLUGIN_PATH&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;      #CONNECT_PLUGIN_PATH: &amp;quot;/usr/share/java,/usr/share/confluent-hub-components&amp;quot;
      CONNECT_PLUGIN_PATH: &amp;quot;\
        /usr/share/java/kafka,\
        /usr/share/confluent-hub-components,\
        /usr/share/java/kafka-connect-jdbc,\
        /etc/kafka-connect/jars&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;while ! docker logs connect 2&amp;gt;&amp;amp;1 | grep -i &amp;quot;INFO Kafka Connect started&amp;quot; ; do
     sleep 1
done
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;[2020-03-02 22:32:15,768] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect)
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm curlimages/curl:7.68.0 \
    -X POST \
    -s \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{ &amp;quot;name&amp;quot;: &amp;quot;quickstart-jdbc-source&amp;quot;, &amp;quot;config&amp;quot;: { &amp;quot;connector.class&amp;quot;: &amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;: 1, &amp;quot;connection.url&amp;quot;: &amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;, &amp;quot;mode&amp;quot;: &amp;quot;incrementing&amp;quot;, &amp;quot;incrementing.column.name&amp;quot;: &amp;quot;id&amp;quot;, &amp;quot;timestamp.column.name&amp;quot;: &amp;quot;modified&amp;quot;, &amp;quot;topic.prefix&amp;quot;: &amp;quot;quickstart-jdbc-&amp;quot;, &amp;quot;poll.interval.ms&amp;quot;: 1000 } }&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;io.confluent.connect.jdbc.JdbcSourceConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;connection.url&amp;quot;:&amp;quot;jdbc:mysql://quickstart-mysql:3306/connect_test?user=root&amp;amp;password=confluent&amp;quot;,&amp;quot;mode&amp;quot;:&amp;quot;incrementing&amp;quot;,&amp;quot;incrementing.column.name&amp;quot;:&amp;quot;id&amp;quot;,&amp;quot;timestamp.column.name&amp;quot;:&amp;quot;modified&amp;quot;,&amp;quot;topic.prefix&amp;quot;:&amp;quot;quickstart-jdbc-&amp;quot;,&amp;quot;poll.interval.ms&amp;quot;:&amp;quot;1000&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-jdbc-source&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;source&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;if-error-message-is-received&#34;&gt;If error message is received&lt;/h3&gt;
&lt;p&gt;Make sure MySQL-JDBC JAR file is correctly mounted to container.&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect env | grep -e &amp;quot;^CONNECT_PLUGIN_PATH&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;CONNECT_PLUGIN_PATH=/usr/share/java/kafka,/usr/share/confluent-hub-components,/usr/share/java/kafka-connect-jdbc,/etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec connect ls -la /etc/kafka-connect/jars
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;total 2312
drwxr-xr-x 2 root root    4096 Mar  2 22:27 .
drwxrwxrwx 1 root root    4096 Mar  2 22:28 ..
-rw-r--r-- 1 root root 2356711 Dec  4 11:44 mysql-connector-java-8.0.19.jar
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Higher the logging level from docker-compose.yml and run again&lt;/p&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;    #CONNECT_LOG4J_ROOT_LOGLEVEL: &amp;quot;DEBUG&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check&#34;&gt;Status Check&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check if new topic is created
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    confluentinc/cp-kafka:5.4.0 \
    kafka-topics --describe \
    --zookeeper zookeeper:2181 \
    --topic quickstart-jdbc-test
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Topic: quickstart-jdbc-test	PartitionCount: 1	ReplicationFactor: 1	Configs:
    Topic: quickstart-jdbc-test	Partition: 0	Leader: 1	Replicas: 1	Isr: 1
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker exec schema-registry \
    kafka-avro-console-consumer \
    --bootstrap-server broker:29092 \
    --topic quickstart-jdbc-test \
    --from-beginning \
    --property print.key=true \
    --max-messages 10 | \
    grep -e &amp;quot;^null&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;null	{&amp;quot;id&amp;quot;:1,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;alice@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;engineering&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:2,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:3,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:4,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:5,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:6,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:7,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:8,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:9,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
null	{&amp;quot;id&amp;quot;:10,&amp;quot;name&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob&amp;quot;},&amp;quot;email&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;bob@abc.com&amp;quot;},&amp;quot;department&amp;quot;:{&amp;quot;string&amp;quot;:&amp;quot;sales&amp;quot;},&amp;quot;modified&amp;quot;:1583188155000}
Processed a total of 10 messages
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;sink-connector&#34;&gt;Sink Connector&lt;/h2&gt;
&lt;h3 id=&#34;add-sink-connector&#34;&gt;Add sink connector&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Call the API of connect
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X POST \
    -H &amp;quot;Content-Type: application/json&amp;quot; \
    --data &#39;{&amp;quot;name&amp;quot;: &amp;quot;quickstart-avro-file-sink&amp;quot;, &amp;quot;config&amp;quot;: {&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;, &amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;, &amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;, &amp;quot;file&amp;quot;: &amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;}}&#39; \
    http://connect:8083/connectors
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;config&amp;quot;:{&amp;quot;connector.class&amp;quot;:&amp;quot;org.apache.kafka.connect.file.FileStreamSinkConnector&amp;quot;,&amp;quot;tasks.max&amp;quot;:&amp;quot;1&amp;quot;,&amp;quot;topics&amp;quot;:&amp;quot;quickstart-jdbc-test&amp;quot;,&amp;quot;file&amp;quot;:&amp;quot;/tmp/quickstart/jdbc-output.txt&amp;quot;,&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;},&amp;quot;tasks&amp;quot;:[],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&#34;status-check-sink&#34;&gt;Status check (Sink)&lt;/h3&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Check connector status through API
docker run \
    --net=&amp;quot;${CONNECT_NET}&amp;quot; \
    --rm \
    curlimages/curl:7.68.0 \
    -s -X GET http://connect:8083/connectors/quickstart-avro-file-sink/status
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;{&amp;quot;name&amp;quot;:&amp;quot;quickstart-avro-file-sink&amp;quot;,&amp;quot;connector&amp;quot;:{&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;},&amp;quot;tasks&amp;quot;:[{&amp;quot;id&amp;quot;:0,&amp;quot;state&amp;quot;:&amp;quot;RUNNING&amp;quot;,&amp;quot;worker_id&amp;quot;:&amp;quot;connect:8083&amp;quot;}],&amp;quot;type&amp;quot;:&amp;quot;sink&amp;quot;}
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# if using docker-machine
if [ docker-machine &amp;gt;/dev/null 2&amp;gt;&amp;amp;1 ]
then
    docker-machine ssh confluent -- cat /tmp/quickstart/file/jdbc-output.txt
else
    cat /tmp/quickstart/file/jdbc-output.txt
fi
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Struct{id=1,name=alice,email=alice@abc.com,department=engineering,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=2,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=3,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=4,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=5,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=6,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=7,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=8,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=9,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
Struct{id=10,name=bob,email=bob@abc.com,department=sales,modified=Mon Mar 02 22:29:15 UTC 2020}
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;docker-compose stop
&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Stopping control-center   ...
Stopping quickstart-mysql ...
Stopping connect          ...
Stopping schema-registry  ...
Stopping broker           ...
Stopping zookeeper        ...
[1Bping zookeeper        ... [32mdone[0m
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&#34;references&#34;&gt;References&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&#34;&gt;https://docs.confluent.io/5.0.0/installation/docker/docs/installation/connect-avro-jdbc.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&#34;&gt;https://www.confluent.io/blog/kafka-connect-deep-dive-jdbc-source-connector/#no-suitable-driver-found&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&#34;&gt;https://rmoff.net/post/kafka-connect-change-log-level-and-write-log-to-file/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&#34;&gt;https://stackoverflow.com/questions/25503412/how-do-i-know-when-my-docker-mysql-container-is-up-and-mysql-is-ready-for-taking&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
</description>
    </item>
    
  </channel>
</rss>
